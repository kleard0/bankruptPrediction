# -*- coding: utf-8 -*-
"""prediction_failliteEn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zjbzt60kiJAthAENGM-Auu0KLKNjzrYd

# Importation des bibliothèques
"""

from google.colab import drive # pour importer le dataset depuis drive
import pandas as pd # pr manipuler les dataframes
import numpy as np # pour créer des matrices
import matplotlib.pyplot as plt # pour tracer des graphiques
import seaborn as sns # pour la visualisation de la data

"""# Chargement du dataset"""

drive.mount('/content/drive')
dataset = pd.read_csv('/content/drive/MyDrive/Projet-MachineLearning/dataset.csv') # chemin vers le dataset
print(dataset.head())

"""# Comprendre le dataset"""

# Pour connaitre le taille du dataset
print(dataset.shape)
#print(dataset.columns)

"""Il s'agit d'un gros dataset (96 features)

# Séparation des features et de la cible
"""

X = dataset.drop('Bankrupt?', axis=1)
y = dataset['Bankrupt?']
print(y.head())

"""# Analyse des données"""

sns.set_style('whitegrid')
sns.countplot(x='Bankrupt?', data=dataset, palette='RdBu_r')

"""On remarque ici que la majorité des entreprises présentes dans le dataset ne sont pas en faillite , environ 6600 pour environ 200 entreprises en faillite"""

print(dataset.columns)

sns.histplot(dataset[' Net Value Per Share (A)'], kde=False, color="darkred", bins=30)

print(dataset.info())

"""Je vais maintenant supprimer les colonnes identiques"""

dataset = dataset.drop([' Net Value Per Share (B)', ' Net Value Per Share (C)'], axis=1)
print(dataset.info())

"""Les données sont complètes"""

sns.heatmap(dataset.isnull(), cmap='viridis')

"""On peut ainsi vérifier graphiquement qu'il ne manque aucune données

# Separation des données train et test
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(dataset.drop('Bankrupt?',axis=1),
                                                    dataset['Bankrupt?'], test_size=0.10,random_state=101)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""# Regression logitisque pour la classification"""

from sklearn.linear_model import LogisticRegression
Logismodel = LogisticRegression(solver='liblinear')
# entrainement
Logismodel.fit(X_train,y_train) # calcul les différents teta du modèles (fonction sigmoide)

"""# Evaluation"""

predictions = Logismodel.predict(X_test)
from sklearn.metrics import classification_report #rapport de classification
print(classification_report(y_test,predictions)) # on compte les valeurs réelles et les prédictions

"""Le modèle n'est parvenu à prédire aucune entreprise en faillite, 2 possibilités : Sois mon code est mauvais (très propable), sois mon dataset contient trop peu d'entreprise en faillite pour l'entrainement du modèle. Je vais reesayer de prédire cela avec des arbres de décisions.  """

from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test,predictions))
tn, tp, fn, fp = confusion_matrix(y_test,predictions).ravel()
print(tn, tp, fn, fp)

from sklearn.metrics import RocCurveDisplay
fpr, tpr, thresholds = roc_curve(y_test, Logismodel.predict_proba(X_test)[:, 1])
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()
plt.show()

"""Essayer -> Forêts aléatoires (Random Forests) ou Arbres de décision (Decision Trees) ou reseau neuronne


"""

